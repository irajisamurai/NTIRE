{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yokoyama/.pyenv/versions/anaconda3-2023.07-2/envs/IRS/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch as th\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.distributed as dist\n",
    "import cv2\n",
    "import csv\n",
    "import tqdm\n",
    "sys.path.insert(0, \"../../\")\n",
    "from utils.metrics import PSNR, SSIM, LPIPS\n",
    "from utils import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_scores_to_csv(out_path, start_step, pre_model, scores):\n",
    "    header = ['pre-model', 'start step'] + list(scores.keys())\n",
    "    mode = 'w' if not os.path.isfile(out_path) else 'a'\n",
    "    with open(out_path, mode, newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if mode == 'w':\n",
    "            writer.writerow(header)\n",
    "        writer.writerow([pre_model] + [start_step] + [i[0] for i in scores.values()])\n",
    "\n",
    "def reverseChannel(img):\n",
    "  # 画像コピー\n",
    "  dst = img.copy()\n",
    "  # チャネル入れ替え\n",
    "  dst[:, :, 0] = img[:, :, 2]\n",
    "  dst[:, :, 2] = img[:, :, 0]\n",
    "\n",
    "  return dst\n",
    "\n",
    "def compute_score(all_images_gt_raw, all_images_pred_raw, start_step, pre_model):\n",
    "    metrics = ('psnr', 'ssim', 'lpips')\n",
    "    device = 'cpu'\n",
    "    boundary_ignore = 40\n",
    "    metrics_all = {}\n",
    "    scores = {}\n",
    "    for m in [\"psnr\",\"ssim\",\"lpips\"]:\n",
    "        if m == 'psnr':\n",
    "            loss_fn = PSNR(boundary_ignore=boundary_ignore)\n",
    "        elif m == 'ssim':\n",
    "            loss_fn = SSIM(boundary_ignore=boundary_ignore, use_for_loss=False)\n",
    "        elif m == 'lpips':\n",
    "            loss_fn = LPIPS(boundary_ignore=boundary_ignore)\n",
    "            loss_fn.to(device)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric: {m}\")\n",
    "        metrics_all[m] = loss_fn\n",
    "        scores[m] = []\n",
    "\n",
    "    scores = {k: [] for k, v in scores.items()}\n",
    "    all_images_gt_raw = th.cat(all_images_gt_raw)\n",
    "    all_images_pred_raw = th.cat(all_images_pred_raw)\n",
    "\n",
    "    for m, m_fn in metrics_all.items():\n",
    "        metric_value = m_fn(all_images_pred_raw, all_images_gt_raw).cpu().item()\n",
    "        scores[m].append(metric_value)\n",
    "        logger.log(f\"{m} is {metric_value}\")\n",
    "\n",
    "    out_path = os.path.join(\"official/lpips\", f\"score.csv\")\n",
    "    write_scores_to_csv(out_path, start_step, pre_model, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yokoyama/.pyenv/versions/anaconda3-2023.07-2/envs/IRS/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/yokoyama/.pyenv/versions/anaconda3-2023.07-2/envs/IRS/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/yokoyama/.pyenv/versions/anaconda3-2023.07-2/envs/IRS/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Logging to /tmp/bsrd-2024-03-21-10-17-23-350664/bsrd-2024-03-21-10-17-23-350754\n",
      "psnr is 28.048084259033203\n",
      "ssim is 0.8622182011604309\n",
      "lpips is 0.037064939737319946\n"
     ]
    }
   ],
   "source": [
    "gt_path = \"/home/yokoyama/image-restoration-sde/codes/config/deshadow/official/gt\"\n",
    "pre_path = \"/home/yokoyama/image-restoration-sde/codes/config/deshadow/official/timestep5\"\n",
    "all_images_gt_raw = []\n",
    "all_images_pred_raw = []\n",
    "#img_list = os.listdir(gt_path)\n",
    "img_list = os.listdir(gt_path)\n",
    "for img in img_list: \n",
    "    gt = os.path.join(gt_path,img)\n",
    "    pre = os.path.join(pre_path,img)\n",
    "    gt_img = cv2.imread(gt, cv2.IMREAD_UNCHANGED).astype(np.float32) / 255.\n",
    "    pre_img = cv2.imread(pre, cv2.IMREAD_UNCHANGED).astype(np.float32) / 255.\n",
    "    gt_img = th.unsqueeze(th.from_numpy(np.ascontiguousarray(np.transpose(gt_img, (2, 0, 1)))).float(), dim=0)[:, [2, 1, 0]]\n",
    "    pre_img = th.unsqueeze(th.from_numpy(np.ascontiguousarray(np.transpose(pre_img, (2, 0, 1)))).float(), dim=0)[:, [2, 1, 0]]\n",
    "    all_images_gt_raw.append(gt_img)\n",
    "    all_images_pred_raw.append(pre_img)\n",
    "compute_score(all_images_gt_raw, all_images_pred_raw, start_step=\"5_T\", pre_model=\"unknown\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
